# 1장 한눈에 보는 머신러닝

---

## 1.1 머신러닝이란?

- 머신러닝
  - 정의: 데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학 or 예술
  - 예시: 스팸메일 필터링
  - 많은 양의 데이터를 통해 학습하는 것이 중요



## 1.2 왜 머신러닝을 사용하는가?

- 스팸필터 만드는 방법 (전통적)

  1) 스팸에 주로 나타나는 단어 확인 (제목, 보낸이의 이름, 메일주소, 본문 등)

  2) 패턴을 감지하는 알고리즘 작성, 패턴 발견 시 스팸으로 분류

  3) 프로그램을 테스트 및 론칭할 만큼 충분한 성능 나올 때까지 1,2단계 반복

  ![image-20210131204059496](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210131204059496.png)

  - 새로운 패턴이 나타날 경우 패턴 입력 필요

- 스팸필터 만드는 방법 (머신러닝)

  - 스팸에 자주 나타나는 패턴 감지 및 학습

  ![image-20210131205548205](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210131205548205.png)

  - 새로운 패턴이 나타날 경우 스스로 데이터 학습 가능

  ![image-20210131210134874](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210131210134874.png)

- 전통적 방식이 복잡하거나 알려진 알고리즘이 없는 문제

  - 음성인식: 각 단어를 녹음한 샘플을 학습 후 알고리즘 작성

- 알고리즘을 통한 학습 가능

  - 머신러닝 알고리즘이 학습한 것 조사
  - 대용량 데이터 분석 시 겉으로 보이지 않는 패턴 발견 가능 (데이터 마이닝)

![image-20210131213746909](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210131213746909.png)

- 머신러닝이 뛰어난 분야
  - 기존 솔루션으로 많은 수동 조정과 규칙이 필요한 문제
  - 전통적인 방식으로는 해결 방법이 없는 복잡한 문제
  - 유동적인 환경
  - 복잡한 문제와 대량의 데이터에서 통찰 얻기



## 1.3 애플리케이션 사례

- 생산 라인에서 제품 이미지를 분석해 자동으로 분류하기 (CNN)
- 뇌를 스캔하여 종양 진단하기 (CNN)
- 자동으로 뉴스기사 분류하기 (NLP, RNN, CNN, 트랜스포머)
- 토론 포럼에서 부정적인 코멘트 자동으로 구분하기 (NLP)
- 긴 문서 자동으로 요약하기 (NLP)
- 챗봇 또는 개인 비서 만들기 (NLP,NLU)
- 다양한 성능 지표를 기반으로 회사의 내년도 수익 예측하기 (회귀, CNN, RNN, 트랜스포머)
- 음성 명령에 반응하는 앱 만들기 (RNN, CNN, 트랜스포머)
- 신용 카드 부정 거래 감지하기 (이상치 탐지 작업)
- 구매 이력을 기반으로 고갱을 나누고 각 집합마다 다른 마케팅 전략을 계획하기 (군집)
- 고차원의 복잡한 데이터셋을 명확하고 의미있는 그래프로 표현하기 (데이터 시각화)

- 과거 구매 이력을 기반으로 고객이 관심을 가질 수 있는 상품 추천하기 (추천 시스템)
- 지능형 게임 봇 만들기 (보통 강화 학습)



## 1.4 머신러닝 시스템의 종류

- 지도, 비지도, 준지도, 강화 학습
- 온라인 학습과 배치 학습
- 사례 기반 학습과 모델 기반 학습



### 1.4.1 지도 학습과 비지도 학습

- 학습하는 동안의 감독 형태나 정보량에 따른 분류

---

#### 1.지도학습

- 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함됨

- 분류가 전형적인 지도 학습 작업

![image-20210201140604759](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201140604759.png)

- 예측 변수라 부르는 특성을 이용해 타깃 수치 예측(회귀)

![image-20210201141130159](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201141130159.png)

- 회귀와 분류의 알고리즘은 서로 이용 가능
- 로지스틱 회귀: 클래스에 속할 확률 출력
- 지도학습 알고리즘 예시
  - k-최근접 이웃
  - 선형 회귀
  - 로지스틱 회귀
  - 서포트 백터 머신
  - 결정트리와 랜덤포레스트
  - 신경망

---

#### 2.비지도 학습

- 훈련 데이터에 레이블 존재x

![image-20210201141632877](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201141632877.png)

- 비지도 학습 알고리즘
  - 군집
    - k-평균
    - DBSCAN
    - 계층 군집 분석
    - 이상치 탐지와 특이치 탐지
    - 원-클래스
    - 아이솔레이션 포레스트
  - 시각화와 차원 축소
    - 주성분 분석
    - 커널 PCA
    - 지역적 선형 임베딩
    - t-SNE
  - 연관 규칙 학습
    - 어프라이어리
    - 이클렛

- 비지도 알고리즘 예시

1. 블로그 방문자(군집)
   1. 방문자 사이의 연결고리 찾기
   2. 계층 군집 알고리즘

![image-20210201142654953](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201142654953.png)

  2. 시각화 알고리즘

       		1. 대규모의 고차원 데이터 입력
              		2. 도식화 가능한 2D or 3D 표현 생성
              		3. 데이터 형태 파악 가능

     ![image-20210201143302892](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201143302892.png)

  3. 차원 축소

       		1. 상관관계가 있는 여러 특성을 하나로 합치는 것(특성추출)

  4. 이상치 탐지(부정 거래 방지)

       		1. 신용카드 거래 감지
              		2. 제조 결함 감지
              		3. 이상치 제거

![image-20210201145115485](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201145115485.png)

5. 특이치 탐지 (이상치 탐지와 유사)
     1. 완전히 비어있는 훈련 세트 준비
     2. 이상치 탐지와 약간의 차이점 존재

6. 연관 규칙 학습
     1. 슈퍼마켓 예시
     2. 바비큐 소스 + 감자 = 스테이크 구매
     3. 연관 규칙을 통한 진열 위치 선정

---

#### 3.준지도 학습

- 레이블이 일부만 존재할 경우
  - 예시: 구글 포토 호스팅 서비스
- 지도학습(DBN) + 비지도 학습(RBM)

![image-20210201145746726](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201145746726.png)

#### 4.강화학습

- 에이전트: 학습하는 시스템
- 환경을 관찰해서 행동을 실행하고 그 결과로 보상 또는 벌점 부여
- 가장 큰 보상을 얻기 위한 정책을 학습

![image-20210201150226660](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201150226660.png)



### 1.4.2 배치학습과 온라인 학습

- 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부

---

#### 1. 배치학습

- 점진적 학습 불가능 -> 가용한 데이터를 모두 사용하여 훈련
- 오프라인에서 수행(시간과 자원을 많이 소모하기 때문)
- 시스템 훈련 후 제품에 적용하면 학습 불가능
- 새로운 데이터 학습 시 시스템 전체의 새로운 버전 필요
- 훈련이 자주 일어나야 함
- 빠르게 변하는 데이터 이용에는 더 능동적인 방법 필요
- 훈련마다 전체 데이터 셋이 필요하기 떄문에 많은 컴퓨팅 자원도 필요
- 자원이 제한된 시스템이 스스로 학습해야 할 떄 많은 양의 데이터와 자원을 사용하면 문제 발생

---

#### 2. 온라인 학습

- 데이터를 한 개씩 순차적 또는 **미니배치**라 부르는 작은 묶음 단위로 주입하여 시스템 훈련
- 데이터가 도착하는 대로 학습 가능

![image-20210201152846632](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201152846632.png)

- 연속적으로 데이터를 받고 빠른 변화에 적응해야 하는 시스템에 적합
- 컴퓨팅 자원이 제한된 경우에도 좋은 선택
- 컴퓨터 한 대의 메인 메무리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에 용이

![image-20210201162015957](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201162015957.png)

- 학습률: 변화하는 데이터에 얼마나 빠르게 적응하는지
  - 학습률 high: 데이터에 빠르게 적응하지만 예전 데이터를 잊어버림
  - 학습률 low: 시스템 관성이 커져 느리게 학습, 새로운 데이터의 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐
- 문제점
  - 나쁜 데이터 주입 시 시스템의 성능 감소(검색 순위 조작)

---

### 1.4.3 사례 기반 학습과 모델 기반 학습

- 어떻게 **일반화**되는가에 따른 분류
- 새로운 샘플에 잘 작동하는 모델을 만드는게 목표



#### 1.사례 기반 학습

1. 시스템이 훈련 샘플을 기억 (학습)
2. 유사도 측정 -> 새로운 데이터와 학습한 샘플을 비교 및 일반화

![image-20210201170326097](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201170326097.png)

#### 2.모델 기반 학습

- 샘플들의 모델 생성 후 예측

![image-20210201170449170](C:\Users\sma05\AppData\Roaming\Typora\typora-user-images\image-20210201170449170.png)

- 무작위성을 가지지만 규칙성을 가지는 모델
- 선형함수로 만듦(모델선택)
- 모델 파라미터를 통해 선형 모델 생성
- 파라미터 생성 방법
  - 효용함수(+), 비용함수(-) 정의
  - 선형 회귀 알고리즘: 훈련 데이터를 통해 가장 잘 맞는 선형모델 파라미터 생성(훈련)

```python
# 예제 코드
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn.linear_model

# 데이터 적재
oecd_bli = pd.read_csv(datapath + "oecd_bli_2015.csv", thousands=',')
gdp_per_capita = pd.read_csv(datapath + "gdp_per_capita.csv",thousands=',',delimiter='\t',
                             encoding='latin1', na_values="n/a")

# 데이터 준비
country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]

# 데이터 시각화
country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction')
plt.show()

# 선형 모델 선택
model = sklearn.linear_model.LinearRegression()

# 모델 훈련
model.fit(X, y)

# 키프로스에 대한 예측
X_new = [[22587]]  # 키프로스 1인당 GDP
print(model.predict(X_new)) # 출력 [[ 5.96242338]]
```

- 정리 
  - 데이터 분석
  - 모델 선택
  - 훈련 데이터로 모델 훈련
  - 새로운 데이터에 모델 적용 및 예측(추론), 일반화

---

## 1.5 머신러닝의 주요 도전 과제

- `나쁜 알고리즘`과 `나쁜 데이터` 가 문제가 됨



### 1.5.1 충분하지 않은 양의 훈련 데이터

- 머신러닝을 실행하기 위해서는 정말 많은 양의 훈련 데이터가 필요

- 데이터의 양이 늘어날수록 테스트 정확도가 올라감



### 1.5.2 대표성 없는 훈련 데이터

- 일부 데이터가 빠져있을 경우 대표성이 불완전

- 대표성이 없는 훈련데이서 사용시 정확한 예측 불가능
- 샘플이 작을 경우 **샘플링 잡음**, 표본 추출 방법이 잘못될 경우 **샘플링 편향** 발생



### 1.5.3 낮은 품질의 데이터

- 에러, 이상치, 잡음으로 가득한 훈련데이터(훈련데이터 정제 필요)
- 훈련데이터 정제 필요 경우
  - 일부 샘플의 이상치가 명확할 경우 무시하거나 고치기
  - 일부 샘플의 특성 누락시 어떻게 다룰 것인지 결정



### 1.5.4 관련 없는 특성

- 훈련에 사용할 좋은 특성을 찾는 것이 핵심 요소 (특성 공학)
- 특성 공학
  - 특성 선택: 가지고 있는 특성 중 훈련에 가장 유용한 특성 선택
  - 특성 추출: 특성을 결합하여 더 유용한 특성을 만듦
  - 새로운 데이터를 수집하여 새 특성을 만듦



### 1.5.5 훈련 데이터 과대적합

- 과대적합: 과도한 일반화
  - 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생
  - 해결방안
    - 파라미터 수가 적은 모델 선택, 모델에 제약을 가해 단순화
    - 훈련 데이터를 더 많이 모음
    - 훈련 데이터의 잡음을 줄임(오류 데이터 수정 및 이상치 제거)
- 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 **규제**사용 - 자유도 설정
- 학습 중 적용하는 규제의 양을 하이퍼파라미터가 결정



### 1.5.6 훈련 데이터 과소적합

- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생
- 해결방안
  - 모델 파라미터가 더 많은 강력한 모델 선택
  - 학습 알고리즘에 더 좋은 특성 제공 (특성 공학)
  - 모델의 제약을 줄임



### 1.5.7 한걸음 물러서서

- 정리
  - 머신러닝은 명시적은 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것
  - 여러 종류의 머신러닝 시스템 존재
  - 머신러닝 프로젝트에서는 훈련 세트에 데이터를 모아 학습 알고리즘에 주입
  - 훈련 세트가 너무 작거나, 대표성이 없는 데이터이거나 잡음이 많고 관련 없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않음, 과소적합이나 과대적합을 피해야함

---

## 1.6 테스트와 검증

- 모델이 얼마나 잘 일반화될지 확인하는 방법: 실제 적용 및 모니터링
- 훈련데이터를 **훈련세트**와 **테스트 세트**로 나누어 훈련 및 테스트 진행
- 일반화 오차: 새로운 샘플에 대한 오류 비율
- 오차의 추정값 도출
  - ex) 훈련 오차가 낮지만 일반화 오차가 높다면 훈련데이터에 과대적합 되어있다는 뜻



### 1.6.1 하이퍼파라미터 튜닝과 모델 선택

1. 테스트 세트를 통해 모델평가
2. 규제를 적용하기 위한 하이퍼파라미터 값 선택
3. 최적화 하이퍼파라미터 값을 구해도 실제 서비스에서 오차가 커짐 -> 테스트 세트에 최적화된 모델을 만들었기 때문



- 해결방법

  - 홀드아웃 검증
    - 훈련 세트 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택 
    - 검증 세트 도출
    - 줄어든 훈련세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련
    - 검증세트에서 가장 높은 성능을 내는 모델을 선택
    - 검증 후 전제 훈련 세트에서 다시 훈련하여 최종 모델 생성
    - 최종 모델을 테스트세트에서 평가 후 일반화 오차 추정
  - 교차검증
    - 작은 검증 세트를 여러 개 사용하여 반복적인 교차검증 수행으로 홀드아웃 검정의 허점 보완
    - 훈련 시간이 검증 세트의 개수에 비례해 늘어난다는 단점 존재

- 데이터 불일치

  - 많은 양의 데이터가 대표성을 갖지 못하는 경우 발생
  - 검증 세트와 테스트 세트에 대표자료가 배타적으로 포함되어야 함
  -  훈련 데이터의 일부를 떼어내어 또 다른 세트 생성(훈련-개발 세트)
  - 검증세트에서 나쁜 성능을 낸다면 데이터 불일치에서 오는 것
  - 훈련-개발 세트에서 잘 작동하지 않으면 훈련세트에 과대적합된 것

  